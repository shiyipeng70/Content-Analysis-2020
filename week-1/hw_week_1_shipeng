import lucem_illud_2020
import nltk 
#nltk.download()
#from nltk.book import * 
import pandas as pd 
import scipy
import sklearn.manifold
import urllib.parse
import spacy
import matplotlib.pyplot as plt
from urllib.request import urlopen
import spacy
from nltk.text import Text

text_url = "http://www.gutenberg.org/files/12345/12345.txt"
raw = urlopen(text_url).read()
type(raw)
len(raw)


def clean_raw_text(raw_text):

    text = raw_text.decode('utf-8')
    clean_text = text.replace("\r","").replace("\n","").replace("_","").replace("\\","").replace("][","")
    clean_text = clean_text.strip("_")
    #clean_text = clean_text.split(".")

    return clean_text[:10000]
    
clean_text = clean_raw_text(raw)

import en_core_web_sm
nlp = en_core_web_sm.load()

def word_tokenize(clean_text):
    tokenized = []
    doc = nlp(clean_text)
    for token in doc:
        if not token.is_punct and len(token.text.strip())>0:
            tokenized.append(str(token))
    return tokenized

text = word_tokenize(clean_text)


def word_counter(wlist):
    word_count = {}
    for word in wlist:
        word_lower = word.lower()
        if word_lower in word_count:
            word_count[word_lower] += 1 
        else:
            word_count[word_lower] = 1 
    countForWord = {'word':[],'count':[]}
    for key,value in word_count.items():
        
        countForWord['word'].append(key)
        countForWord['count'].append(value)
    return pd.DataFrame(countForWord)


counted_words = word_counter(text)

counted_words.sort_values('count',ascending=False,inplace=True)

fig = plt.figure()
ax = fig.add_subplot(111)
plt.plot(range(len(counted_words)),counted_words['count'])
plt.show()
            
fig = plt.figure()
ax = fig.add_subplot(111)
plt.plot(range(len(counted_words)),counted_words['count'])
ax.set_yscale('log')
ax.set_xscale('log')
plt.show()

Ttext = Text(text)
concordance = Ttext.concordance('great')
common = Ttext.common_contexts(['great'])

normalized_pos=[]
doc= nlp(clean_text)
for token in doc:
    #print(token.text,token.tag_)
    normalized_pos.append((token.text,token.tag_))
    
    condition = len(token)
    nltk.ConditionalFreqDist[condition][token]+=1
