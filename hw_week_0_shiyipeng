import dependencies
import tweepy
from tweepy import OAuthHandler
from tweepy.streaming import StreamListener
import json
from tweepy import Stream
#from Unicode import unidecode
import time
import datetime 
import requests
import bs4
import re
import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()


url = "http://api.twitter.com/1.1/search/tweets.json"

API_key = "dAcQ3xOznkH4weiHNcOCtJlBU"
API_secret = "hXLhDenPi0BXLpiEf21726R6VnIqCdwEF2Bec1If3EE4iU9TIr"
Access_token = "1219979323945443328-xk9kQNKCCtAXN3gk4pOy86YO3cgW4i"
Access_token_secret = "vnn7ylL8qHUwB27nGi7POhFidO9hjWbMDPKan2fDS2CSY"

tracklist = ['#coronavirus','#China','#COVID-19']
tweet_count = 0
n_tweets = 100

class stdOutListener(StreamListener):
    def on_data(self,data):
        global tweet_count
        global n_tweets
        global stream
        if tweet_count < n_tweets:
            print(data)
            tweet_count += 1
            return True
        else:
            stream.disconnect()

    def on_error(self,status):
        print(status)

if __name__ == '__main__':
    l = stdOutListener()
    auth = OAuthHandler(API_key,API_secret)
    auth.set_access_token(Access_token,Access_token_secret)
    stream = Stream(auth,l)
    stream.filter(track=tracklist)


tweets_data_path = "twitter_data.txt"
tweets_data = []
tweets_file = open(tweets_data_path,'r')
for line in tweets_file:
    try:
        tweet = json.loads(line)
        tweets_data.append(tweet)
    except:
        continue

tweets = pd.DataFrame()
tweets['text'] = list(map(lambda tweet : tweet['text'],tweets_data))
tweets['Username'] = list(map(lambda tweet:tweet['user']['screen_name'],tweets_data))
tweets['Timestamp'] = list(map(lambda tweet:tweet['created_at'],tweets_data))

for sentence in tweets['text']:
    vs = analyzer.polarity_scores(sentence)
    print(vs)
